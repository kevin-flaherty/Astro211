{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNo93B_hMQFu"
   },
   "source": [
    "# Python CCD Data Reduction\n",
    "\n",
    "---\n",
    "\n",
    "### Names: [Enter your names here]\n",
    "\n",
    "**Before you do anything else, go to *File -> Save As* and change the filename to include your name or initials. Make any requested edits to that copy.**\n",
    "\n",
    "This notebook walks through the basics of CCD data reduction within python. More detailed instructions (involving more powerful pieces of software) can be found in the CCD Data Reduction Guide written by Matt Craig and Lauren Chambers [https://mwcraig.github.io/ccd-as-book/00-00-Preface](https://mwcraig.github.io/ccd-as-book/00-00-Preface), which itself is based on the [IRAF CCD reduction](http://ircamera.as.arizona.edu/Astr_518/irafguid.pdf) and [stellar photometry](https://www.mn.uio.no/astro/english/services/it/help/visualization/iraf/daophot2.pdf) guides by Phil Massey. \n",
    "\n",
    "You will need various fits images for this lab, which can be found on the Astro Server. Look under Shared -> CCD_Data -> Astro211 and upload all of the files in this folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfa8fOynp596"
   },
   "source": [
    "**New Code**\n",
    "\n",
    "* Open and close a fits file.\n",
    "* Print info about a fits file.\n",
    "* Access the data and the header within a fits file.\n",
    "* Access the elements of a header.\n",
    "* Set the x-axis range of a plot.\n",
    "* Calculate the median along one axis of a multi-dimensional array.\n",
    "* Read in just the header from a fits file.\n",
    "* Add a new keyword to a fits header.\n",
    "* Turn a multi-dimensional array into a one-dimensional array.\n",
    "* `enumerate`\n",
    "* Create a new HDU object\n",
    "* Save the HDU object to a fits file\n",
    "* `/=`, `*=`, `+=`, `-=`\n",
    "* `array.shape`\n",
    "* `np.zeros((dim1,dim2))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NtfY2pngQc7"
   },
   "source": [
    "### Pseudo-code\n",
    "\n",
    "Trying to remember all of the exact syntax of various python statements can often get in the way of figuring out how to set up a program. Knowing whether or not to use a for loop is a separate problem than knowing the exact syntax of a for loop. Pseudo-code uses a mixture of code and plain english to represent a program in a way that avoids any concerns about syntax, but still makes clear how the program is designed to work.\n",
    "\n",
    "As an example, lets consider the function from the first lab that took in an array of numbers and returned the sum of these numbers. The exact python code was:\n",
    "\n",
    " ```\n",
    " def sum_func(array_like):\n",
    "    out_sum = 0\n",
    "    for i in array_like:\n",
    "        out_sum += i\n",
    "    return out_sum\n",
    "```\n",
    "\n",
    "Converting to pseudo-code this becomes:\n",
    "\n",
    "```\n",
    "sum_func(an array of numbers)\n",
    "  Set initial sum to 0\n",
    "  For each element in input array of numbers:\n",
    "    Add element to sum\n",
    "  Return sum\n",
    "```\n",
    "\n",
    "From this pseudo-code you can see that you will need a variable that contains the sum, and you need to know the syntax for looping over the elements in a list. The pseudo-code doesn't worry about exact variable names, or exact syntax, but does include the for loop and the return statement. \n",
    "\n",
    "Now lets consider an example of going in the other direction (converting from psuedo code to actual code). In the first lab you wrote a function that would go through a list of students and their grades and sort the students as either proficient or struggling. The pseudo-code version of this algorithm looks like:\n",
    "\n",
    "```\n",
    "For student and grade in class list\n",
    "  If grade is greater than average grade\n",
    "    Add student to profcient student lest\n",
    "  Else\n",
    "    Add student to struggling student list\n",
    "```\n",
    "\n",
    "This pseudo-code makes it clear that we need to loop over every student in the list, and compare the grade of that student to the average for the class. Based on this comparison the student is either added to the proficient student list or the struggling student list.\n",
    "\n",
    "From this psuedo-code you can imagine how to construct the actual piece of code. You will need lists for proficient students and struggling students, and you need to be able to add new entries to each of these lists. You will need to know the average grade for the class, as well as have a class list that contains names and grades (these may be defined earlier in the code). You will also need to figure out how to loop over the class list in a way that gives you access to both the grade and the student name. The exact python code for completing this task was:\n",
    "\n",
    "```\n",
    "proficient_studnts = []\n",
    "struggling_students = []\n",
    "for i in class_grades:\n",
    "  if float(i[1]) > mean_score:\n",
    "    proficient_students.append(i)\n",
    "  else:\n",
    "    struggling_students.append(i)\n",
    "```\n",
    "\n",
    "There are no formal rules for pseudo-code, or for how detailed to be when writing pseudo-code. Being too general isn't helpful (i.e., replacing the second example with `sort the students based on their grade` is not very helpful) but if you include too much detail then you end up just writing the function. Psuedo-code is best viewed as a tool to help you think about how a piece of code is structured, without worrying about the exact syntax. Include as much, or as little, detail as is helpful for you to understand how the code operates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TVxRbwDNRTj"
   },
   "source": [
    "### Reducing CCD Data\n",
    "\n",
    "Any data taken at an observatory must go through a number of steps before it can be used for scientific analysis. This includes correcting for the bias level, the dark current, and inhomogeneities in the sensitivity across the detector. These contributions can be accounted for with the use of bias frames, dark frames, and flat field images. *Bias frames* are images with an exposure time of zero, and represent the number of counts that each pixel starts with before any contribution from the sky, or other sources of electrons. *Dark frames* represent the contribution from the thermal electrons; they are matched to the exposure time of the science image since the thermal signal increases with time. *Flat field frames* are images of a uniformly illuminated object. Any differences in the recorded signal between different pixels in a flat field image are most likely due to differences in the response rate of different pixels.\n",
    "\n",
    "Bias and dark frames are subtracted from the science image, while a normalized flat field frame is divided off to produce a processed image. The formula for constructing a useable science image from a raw image is:\n",
    "\n",
    "$science = \\frac{raw - bias - dark}{flat}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646234512037,
     "user": {
      "displayName": "Hector Mendoza",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11173685038243693514"
     },
     "user_tz": 300
    },
    "id": "DVfGWuQoMCST"
   },
   "outputs": [],
   "source": [
    "# Load in the necessary packages\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0uWePmTOb9d"
   },
   "source": [
    "### Bias Frames (and basic fits handling in python)\n",
    "\n",
    "First, lets read in a bias frame. We will look at the `CalR-0001Bias.fit` file.\n",
    "\n",
    "\n",
    "We will use the `astropy` package, which includes the ability to read in fits files. Fits files are read into an HDUList object, which is a flexible data type that contains the data as well as the header. [More info about fits files in python can be found on the [astropy.io.fits documentation page.]((https://docs.astropy.org/en/stable/io/fits/)]\n",
    "\n",
    "Below, after reading in the fits file into the variable `bias1`, we use the `.info()` function to print information about the fits file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "error",
     "timestamp": 1646234518815,
     "user": {
      "displayName": "Hector Mendoza",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11173685038243693514"
     },
     "user_tz": 300
    },
    "id": "h3rpqR6UObC2",
    "outputId": "ea53be81-cea4-4ba0-fff6-8fe239e02e04"
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# Read in a bias frame\n",
    "bias1 = fits.open('CalR-0001Bias.fit')\n",
    "bias1.info() # print basic info about the fits file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juMqvzmiQHhC"
   },
   "source": [
    "The output of the `.info()` function says that this fits file has one extension (since there is only one line of output), and has dimensions 1024x1024. The data and header for this extension can be accessed using the `.data` and `.header`, as shown below. If other extensions existed, they could be accessed in a similar manner, by simply changing the index. All of the files that you will look at today will only have one extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIz9_-9MPVix"
   },
   "outputs": [],
   "source": [
    "bias_data = bias1[0].data\n",
    "bias_header = bias1[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_qst8f6QlQZ"
   },
   "source": [
    "The header is a dictionary and individual elements, such as the image type and the exposure time, can be accessed as with dictionaries. We can print off all of the keys to see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju8wlfltQ5o5"
   },
   "outputs": [],
   "source": [
    "print('Image Type: {}'.format(bias_header['imagetyp'])) #Image type header keyword\n",
    "print('Exposure Time: {}'.format(bias_header['exptime'])) #Exposure time image keyword\n",
    "print('---')\n",
    "for key in bias_header.keys():\n",
    "  print(key) #Print out the keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQYhjJ3QRMIq"
   },
   "source": [
    "The data themselves are a numpy array, and the flux in individual pixels can be accessed in the same way as with any two-dimensional array. As we saw based on the result from the `.info()` function the data has dimensions 1024x1024. We can verify the dimensions by looking at the shape of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBos024aRbok"
   },
   "outputs": [],
   "source": [
    "print('Shape of the array: {}'.format(bias_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4dtgkAJRhL-"
   },
   "source": [
    "Since it is a regular numpy array, we can access the flux values at various locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uryBEkF3RlL3"
   },
   "outputs": [],
   "source": [
    "print('Flux in corner element: {}'.format(bias_data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqtTR_VxSisq"
   },
   "source": [
    "The `convenience_functions.py` file, available on Glow, contains a function called `show_image` that can help in displaying images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDzHM6YYS6-T"
   },
   "outputs": [],
   "source": [
    "from convenience_functions import show_image #<- This loads the show_image function\n",
    "show_image(bias_data,cmap='gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfX12BR0TId0"
   },
   "source": [
    "As a bias frame, this image represents the state of the detector before it has been exposed to light. Variations in pixel value are partly due to read noise, as well as defects in the detector. We can look at the distribution of pixel values using the `hist` function from matplotlib, which we met in the first lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teNu7DPBTY3U"
   },
   "outputs": [],
   "source": [
    "plt.hist(bias_data.flatten(),10000,histtype='step')\n",
    "plt.xlim(1300,1700) #<-- What does this line do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXW8gjsYTsrQ"
   },
   "source": [
    "> **Q:** To the above code block, add code to label the X-axis as 'Counts' and add the title 'Distribution of Bias Counts'.\n",
    "\n",
    "> **Q:** What does the `plt.xlim(1300,1700)` line do? You can either look up the answer on the interwebs, use the help function to look at its docstring, or you can play around with the values to see what changes.\n",
    ">\n",
    "> **A: [your answer here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ka25UmAUGsB"
   },
   "source": [
    "### Dark Frames\n",
    "\n",
    "Now lets look at a dark frame.\n",
    "\n",
    "> **Q:** As we did with the bias frame, read in the first dark frame (`CalR-0001Dark.fit`) and display the image using the `show_image` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LqZf97TUFQd"
   },
   "outputs": [],
   "source": [
    "# Read in the dark frame, and display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcjK0rl_Uaf9"
   },
   "source": [
    "The dark frame represents the contribution from thermal electrons. The image was taken with the shutter closed and an exposure time of sixty seconds. The pixel values are only slightly higher than the bias frame, suggesting that the dark current is not very high. We can calculate the dark current by subtracting a bias image, and then dividing the result by the exposure time.\n",
    "\n",
    "> **Q:** The following function calculates the average dark current, in electrons per second, absed on a given dark frame. *But there are errors and missing lines in the function.* Correct the errors and missing lines so that the function runs properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtbtjf1jVQ5O"
   },
   "outputs": [],
   "source": [
    "def calc_dark_current(dark_filename):\n",
    "  dark_image = #Insert code that reads the fits file dark_filename into the variable dark_image\n",
    "  dark_data = dark_image[0].data\n",
    "  dark_header = dark_image[0].bias_header\n",
    "  exp_time = #Insert code that reads the exptime keyword from the header, places this value in the variable exp_time\n",
    "  dark_image.close()\n",
    "  gain = 2.\n",
    "  avg_dark_current = gain*np.mea(dark_data)/exp_time\n",
    "  print('Average Dark current: {:0.2f} e-/sec'.format(avg_current)\n",
    "\n",
    "calc_dark_current(CalR-0001Dark.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18N_j4dSr5KP"
   },
   "source": [
    "> **Q:** Convert the function defined above from code into pseudo-code\n",
    "\n",
    "```\n",
    "[insert answer here, between the sets of three tick-marks]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS-Vv4AgWKCi"
   },
   "source": [
    "### Flat Field\n",
    "\n",
    "Now lets look at the flat field\n",
    "\n",
    "> **Q:** As we did with the bias frame, read in the first flat field frame (`CalR-0001R.fit`). Display the image using the `show_image` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVpgQwtYWXlO"
   },
   "outputs": [],
   "source": [
    "# Read in a flat field, and display the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKK-fwE_WiUl"
   },
   "source": [
    "### Reducing science data\n",
    "\n",
    "A science image needs to be corrected for the dark, bias, and flat field. This can be done based on individual dark, bias, and flat field images but it is much better to combine multiple frames. This is because each frame contains read noise on the individual pixels. By average multiple frames we can reduce the contribution of the read noise.\n",
    "\n",
    "The following introduces how to combine multiple frames, and how to save the output. First we will set up a dictionary that contains the names of all of the calibration files. This includes the bias frames, the dark frames, and the flat field images for each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkyorGMEZnRa"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with the file names of the bias frames, dark frames, and flat field frames\n",
    "data_files = {'biases':['CalR-00%02dBias.fit' % x for x in range(1,11)],\n",
    "              'darks':['CalR-00%02dDark.fit' % x for x in range(1,11)],\n",
    "              'Rflats':['CalR-00%02dR.fit' % x for x in range(1,6)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V90TSoPaLAf"
   },
   "source": [
    "Next we will open each bias frame and save the data into one large master array (`bias_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXSVdPZ7aQ5e"
   },
   "outputs": [],
   "source": [
    "from astropy.utils import data\n",
    "# Read in the bias frames\n",
    "bias_data = np.zeros((len(data_files['biases']),1024,1024)) # First create an empty numpy array with the right dimensions\n",
    "for i,file in enumerate(data_files['biases']):\n",
    "  image = fits.open(file)\n",
    "  bias_data[i,:,:] = image[0].data\n",
    "  image.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qM9S6P1a0jf"
   },
   "source": [
    "In the for loop above, I introduced the `enumerate` function. This function takes in a list and returns two items: the first is an index, and the second is the value of the list at that index. We can see how this works if I run a simple for loop that prints out the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7I4uNMJbFoU"
   },
   "outputs": [],
   "source": [
    "for i,file in enumerate(data_files['biases']):\n",
    "  print(i,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVEn90e3bMKd"
   },
   "source": [
    "As it steps through the elements of the list, the `enumerate` function returns the index at each position, and the value of the list at that position. When employed in the for loop, this allows us to use the file name for reading in the fits file, and then use the index when placing the data within our combined array.\n",
    "\n",
    "Now lets return to the `bias_data` variable. This is a three dimensional array, with dimensions (Number of bias frames) x (Number of rows) x (Number of columns). As with the numpy array, individual elements can be specified using square brackets, but now three indeces need to be specified. The for loop above puts each image into a different portion of the array, so that all of the data is accessible in one array.\n",
    "\n",
    "> **Q:** Which of the following lines of code selects the center pixel of the 1st image? (Delete the incorrect answers)\n",
    ">\n",
    "> `bias_data[512,512,1]`\n",
    ">\n",
    "> `bias_data[1,512,512]`\n",
    ">\n",
    "> `bias_data[0,512,512]`\n",
    ">\n",
    "> `bias_data[512,512,0]`\n",
    "\n",
    "Note that for a 2D image the x-axis (FITS NAXIS1) is the *second* index, while the y-axis is the first index. Selecting out the flux at e.g. x=10, y=45 in the first image would use the code `bias_data[0,44,9]`.\n",
    "\n",
    "> **Q:** Which of the following selects out the pixels in the first image with 220 < x < 240 and 450 < y < 470? (Delete the incorrect answers)\n",
    ">\n",
    "> `bias_data[220:240,450:470,0]`\n",
    ">\n",
    "> `bias_data[450:470,220:240,0]`\n",
    "> \n",
    "> `bias_data[0,220:240,450:470]`\n",
    ">\n",
    "> `bias_data[0,450:470,220:240]`\n",
    "\n",
    "\n",
    "Next we need to combine all of these images into one image. At each pixel position we want to take the median across all of the images. In this way we construct a new image that has the same dimensions as the original image, but has less noise. This could be done use two for loops (one looping over the rows and the other looping over columns), but the median function within numpy has this functionality built in. The following line of code will take the median along the 1st axis at each position in the 2nd and 3rd axis (e.g., at each pixel position, take the median across all of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g_AV7f6dRrL"
   },
   "outputs": [],
   "source": [
    "combined_bias = np.median(bias_data,axis=0) #<- The axis keyword starts counting at zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cnCnouvdY0V"
   },
   "source": [
    "Now lets look at a single bias frame and the combined bias frame side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3G3znmKdcB3"
   },
   "outputs": [],
   "source": [
    "show_image(bias_data[0,:,:],cmap='gray')\n",
    "plt.title('One Bias Frame')\n",
    "\n",
    "show_image(combined_bias,cmap='gray')\n",
    "plt.title('Combined Bias Frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIzt6V9Mdl45"
   },
   "source": [
    "Notice how the combined bias frame looks less grainy. That is because the graininess was due to read noise, which is reduced when taking a median combination of multiple frames.\n",
    "\n",
    "Next we will write out the median-combined bias frame so that we can access it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWB_DBv3dxMn"
   },
   "outputs": [],
   "source": [
    "# Write out the combined bias file\n",
    "\n",
    "# First read in the header from one of the bias files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('CalR-0001Bias.fit') #<- Read in just the header. This saves time and memory\n",
    "hdr['history'] = 'Median combination bias frame' #<- Add a new keyword, with the given value (just like any other dictionary).\n",
    "\n",
    "# Create a new HDU object\n",
    "hdu = fits.PrimaryHDU(combined_bias,hdr)\n",
    "hdu.writeto('combined_bias.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1oxFarBewBF"
   },
   "source": [
    "Now we want to do the same thing for the dark and flat field frames. The procedure is very similar, with two additional considerations:\n",
    "\n",
    "\n",
    "*   We must subtract the bias level from each dark frame before they are median-combined. We want the final combined dark image to only represent the dark current, not the dark current plus the bias level.\n",
    "*   Each flat image must have the bias level subtracted, as well as the dark current. After created a combined flat field image, we then need to normalize this combined image, which we can do by dividing the image by its median value.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeUyTDP0sYQY"
   },
   "source": [
    "\n",
    "> **Q:** In the space below, write out the psuedo-code for processing the flat field frames.\n",
    "\n",
    "```\n",
    "[insert answer here]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mx9PTeZ7sVoT"
   },
   "source": [
    "Lets start with the dark frame.\n",
    "\n",
    "> **Q:** The code below gives the basic outline for creating a median-combined, bias-subtracted dark frame. Insert the necessary lines of code to complete this code block. (There are no intentional errors in this code block, just missing pieces of code.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "825SQrzLhRas"
   },
   "outputs": [],
   "source": [
    "# Now lets do the same for the dark frame, making sure to subtract of the bias\n",
    "\n",
    "# Read in the dark frames\n",
    "dark_data = np.zeros((len(data_files['darks']),1024,1024))\n",
    "for i,file in enumerate(data_files['darks']):\n",
    "  image = fits.open(file)\n",
    "  dark_data[i,:,:] = #Insert code to input the dark image data, while subtracting off the bias\n",
    "  image.close()\n",
    "\n",
    "# Insert code to median combine the dark_data array\n",
    "combined_dark = \n",
    "\n",
    "# Write out the combined dark file\n",
    "# First read in the header from one of the dark files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('CalR-0001Dark.fit')\n",
    "hdr['history'] = 'Median combined dark frame'\n",
    "\n",
    "# Create an HDU object from the data and header, and write out the result.\n",
    "hdu = fits.PrimaryHDU(combined_dark,hdr)\n",
    "hdu.writeto('combined_dark.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2mwXhK9iN0F"
   },
   "outputs": [],
   "source": [
    "show_image(dark_data[0,:,:],cmap='gray')\n",
    "plt.title('One Dark Frame')\n",
    "\n",
    "show_image(combined_dark,cmap='gray')\n",
    "plt.title('Combined Dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVxi8xT7iYQJ"
   },
   "source": [
    "> **Q:** Now repeat for the flat field images. Make sure to subtract off both the bias level and the dark current. The dark current must be scaled to the exposure time of the flat field images. To do this, divide the combined dark current image by the exposure time of the dark current image (120 seconds) to get the dark current per second, and then multiply by the exposure time of the flat field image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wXgkCm4jbw7"
   },
   "outputs": [],
   "source": [
    "from astropy.io.fits import header\n",
    "flat_data = np.zeros((len(data_files['Rflats']),1024,1024))\n",
    "for i,file in enumerate(data_files['Rflats']):\n",
    "  image = fits.open(file)\n",
    "  header = image[0].header\n",
    "  exptime = #Insert code to read in the exposure time from the header\n",
    "  flat_data[i,:,:] = #Insert code to read the data from the image, and subtract both the bias and the scaled dark\n",
    "  image.close()\n",
    "\n",
    "# Insert code to median combine the flat data, and place the results into a variable called combined_flat\n",
    "combined_flat = \n",
    "# Next, normalize the flat field image.\n",
    "#    Both of the following statements are equivalent (we keep one commented out because we don't want to divide twice)\n",
    "combined_flat = combined_flat/np.median(combined_flat)\n",
    "#combined_flat /= np.median(combined_flat)\n",
    "\n",
    "# First read in the header from one of the flat files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('CalR-0001R.fit')\n",
    "hdr['history'] = \"Median combined flat frame\"\n",
    "\n",
    "#Insert code to create a new HDU object, using the combined_flat and hdr.\n",
    "\n",
    "#Save the result as combined_Rflat.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGqjF3vIocDW"
   },
   "outputs": [],
   "source": [
    "show_image(flat_data[0,:,:],cmap='gray')\n",
    "plt.title('One Flat Frame')\n",
    "\n",
    "show_image(combined_flat,cmap='gray')\n",
    "plt.title('Combined Flat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F35ukn0xonZB"
   },
   "source": [
    "Now that we have our master bias, dark, and flat field images, we can apply them to a science image.\n",
    "\n",
    "> **Q:** Below is the beginning of a function that will read in a science image, and then perform the bias/dark/flat corrections. We want to write a function that takes as inputs the filename of the raw image (as a string), the filename of the output file (a string, and it should be different from the original filename), and the name of the bias, dark, and flat field frames. The function reads in the bias, dark, flat field, and science images, performs the necessary calibrations to the science image, and then writes out the calibrated science frame.\n",
    ">\n",
    "> First write out the psuedo-code for this function in the space below.\n",
    "\n",
    "\n",
    "```\n",
    "def process_data():\n",
    "  [insert answer here]\n",
    "```\n",
    "\n",
    "\n",
    "> **Q:** Next, convert from your pseudo-code to actual code in the space below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEP8hG5qpBt3"
   },
   "outputs": [],
   "source": [
    "def process_data(filename,new_filename,bias_file='combined_bias.fits',dark_file='combined_dark.fits',flat_file='combined_Rflat.fits'):\n",
    "\n",
    "  science_image = # Insert code here\n",
    "  science_data = #Insert code here\n",
    "  hdr = #Insert code here\n",
    "  exptime = #Insert code here\n",
    "  \n",
    "\n",
    "  bias_image = #Insert code here\n",
    "  bias_data = #Insert code here\n",
    "\n",
    "\n",
    "  dark_image = #Insert code here\n",
    "  dark_data = #Insert code here\n",
    "\n",
    "\n",
    "  flat_image = #Insert code here\n",
    "  flat_data = #Insert code here\n",
    "\n",
    "\n",
    "  proc_data = #Insert code here\n",
    "\n",
    "  #Insert code here\n",
    "  hdu.writeto(new_filename,overwrite=True)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dS2Qa8wnh2n"
   },
   "source": [
    "Test your code using the following code block (make sure to upload the necessary fits file from Glow to your working directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auLgW4y2qJB1"
   },
   "outputs": [],
   "source": [
    "#Test your code using this code block\n",
    "process_data('M101_MartiC_180-0001.fit','M101_MartiC_180-0001_proc.fits')\n",
    "\n",
    "old_image = fits.open('M101_MartiC_180-0001.fit')\n",
    "old_data = old_image[0].data\n",
    "old_image.close()\n",
    "\n",
    "new_image = fits.open('M101_MartiC_180-0001_proc.fits')\n",
    "new_data = new_image[0].data\n",
    "new_image.close()\n",
    "\n",
    "show_image(old_data,cmap='gray')\n",
    "plt.title('Raw Image')\n",
    "\n",
    "show_image(new_data,cmap='gray')\n",
    "plt.title('Processed Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Now that you know how to process data, you can start to do some analysis with processed data. Let's look at the supernova in M101 from 2023. The files M101_1.fit, M101_2.fit, M101_3.fit, M101_4.fit, and M101_5.fit are images of M101, one taken before the supernova exploded, and the rest taken after the supernova exploded. Use these images to measure how the brightness of the supernova changed with time.\n",
    "\n",
    "To do this:\n",
    "\n",
    "1. Process each of the images using the function that you created.\n",
    "\n",
    "2. Sum up the flux in a small box in a region around the supernova. The box size should be large enough to encompass the supernova, but not include too much contaminating flux from surrounding material in the galaxy. Use the same box size for all three images. For the pre-supernova image, use the location where the supernova shows up in the subsequent images.\n",
    "\n",
    "3. From the header of each image, find the date when the image was collected.\n",
    "\n",
    "4. Plot the flux of the supernova as a function of the number of days since the first image. Make sure to label the axes of the plot. \n",
    "\n",
    "\n",
    "*BONUS: Use loops to simplify your code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3T0hXdgm3wc"
   },
   "source": [
    "#### To turn in this lab, either email me (kmf4) a copy of this notebook, or place your copy in Shared/Astro211_F25/CCD_Reduction folder in the Astro server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CCD_Data_Reduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
