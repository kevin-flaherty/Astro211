{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fb6757",
   "metadata": {},
   "source": [
    "Lets look at the distribution of brightness in the bias and dark frames, and see if taking the median combination has reduced the noise in these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_bias = fits.open('CalR-0001Bias.fit')[0].data\n",
    "single_dark = fits.open('CalR-0001Dark.fit')[0].data\n",
    "single_flat = fits.open('CalR-0001R.fit')[0].data\n",
    "\n",
    "combined_bias = fits.open('combined_bias.fits')[0].data\n",
    "combined_dark = fits.open('combined_dark.fits')[0].data\n",
    "combined_flat = fits.open('combined_Rflat.fits')[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cba739",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(single_bias.flatten(),10000,histtype='step',color='k')\n",
    "plt.hist(combined_bias.flatten(),10000,histtype='step',color='r')\n",
    "plt.xlim(1300,1700)\n",
    "\n",
    "print(np.std(single_bias))\n",
    "print(np.std(single_bias)/np.sqrt(10))\n",
    "print(np.std(combined_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ad789",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(single_dark.flatten(),10000,histtype='step',color='k')\n",
    "plt.hist(combined_dark.flatten(),10000,histtype='step',color='r')\n",
    "plt.xlim(0,1700)\n",
    "\n",
    "print(np.std(single_dark))\n",
    "print(np.std(single_dark)/np.sqrt(5))\n",
    "print(np.std(combined_dark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(single_flat.flatten()/np.median(single_flat),10000,histtype='step',color='k')\n",
    "plt.hist(combined_flat.flatten(),10000,histtype='step',color='r')\n",
    "plt.xlim(0.95,1.05)\n",
    "\n",
    "print(np.std(single_flat/np.median(single_flat)))\n",
    "print(np.std(single_flat/np.median(single_flat))/np.sqrt(5))\n",
    "print(np.std(combined_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747e484",
   "metadata": {},
   "source": [
    "In all three cases the dispersion decreases, but not by as much as you would expect from statistics. This might be because the standard deviation is biased by bright/dead pixels in the data. These pixels are still far from the median, and so artificially broaden the standard deviation.\n",
    "\n",
    "I could have them calculate the fraction of pixels beyond +-3 sigma and compare that to what they expect. If there are more than they expect, then there are bad pixels, and I could talk about how to replace them with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ea506",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbad_bias = np.sum(np.abs(combined_bias-np.median(combined_bias))/np.std(combined_bias)>3)\n",
    "nbad_dark = np.sum(np.abs(combined_dark-np.median(combined_dark))/np.std(combined_dark)>3)\n",
    "nbad_flat = np.sum(np.abs(combined_flat-np.median(combined_flat))/np.std(combined_flat)>3)\n",
    "\n",
    "print(nbad_bias,nbad_dark,nbad_flat,.003*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f358128",
   "metadata": {},
   "source": [
    "The flat field image seems to have more bright/dead pixels than expected, while the bias and dark image has fewer pixels beyond 3 sigma than we would expect. \n",
    "\n",
    "Lets try plotting a Gaussian on top of the historgrams to see how the standard deviations compare with the actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = plt.hist(single_dark.flatten(),10000,histtype='step')\n",
    "bias_std = np.std(combined_dark)\n",
    "print(bias_std)\n",
    "combined_dark[combined_dark>65000] = np.median(combined_dark)\n",
    "print(np.std(combined_dark))\n",
    "#plt.xlim(1300,1700)\n",
    "#print(p[1])\n",
    "#plt.plot(p[1],np.max(p[0])/(2*bias_std**2.)*np.exp(-(p[1]-np.median(p[1]))**2.)/2*bias_std**2.,color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b9b45",
   "metadata": {},
   "source": [
    "## Gaia distances\n",
    "\n",
    "Look at the distribution of distances to the Pleiades\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323280c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(file):\n",
    "  '''\n",
    "    Read in a list of parallaxes, and calculate the average distance.\n",
    "    INPUTS:\n",
    "      file (string): The filename\n",
    "    OUTPUTS:\n",
    "      Prints the average distance\n",
    "    RETURNS:\n",
    "      None\n",
    "  '''\n",
    "  data = np.loadtxt(file,delimiter=',',skiprows=1,dtype='str')\n",
    "  p = np.array([float(x) for x in data[:,4]])\n",
    "  print(np.mean(1000/p))\n",
    "calc_distance('Pleiades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('chiPersei_error_30arcmin_SNR5.csv',delimiter=',',skiprows=1,dtype='str')\n",
    "parallax = np.array([float(x) for x in data[:,4]])\n",
    "parallax_error = np.array([float(x) for x in data[:,5]])\n",
    "p=plt.hist(1000/parallax,100,histtype='step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3247d",
   "metadata": {},
   "source": [
    "There are clearly some outliers that are dragging up the distances.\n",
    "\n",
    "Do they just have large error bars? If that is true then a weighted mean, or a tighter constraint on the SNR would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1000/parallax,parallax_error,'ok')\n",
    "plt.axvline(46)\n",
    "plt.xlabel('distance (pc)')\n",
    "plt.ylabel('unc_p (mas)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(1000/parallax))\n",
    "print(1000/np.mean(parallax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d90b6",
   "metadata": {},
   "source": [
    "Chi Persei (NGC 884), with 30 arcmin window, might work. According to simbad it has an angular size of 15 arcmin, and a parallax of 0.3976\n",
    "\n",
    "H persei (NGC 869). Does that work as well? Simbad says it has an angular size of 16 arcmin and a parallax of 0.3942. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4968f8",
   "metadata": {},
   "source": [
    "## SDSS SQL query\n",
    "\n",
    "Try looking at the distribution of velocities from the Virgo cluster, and see if they are Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+http://github.com/astropy/astroquery.git#egg=astroquery\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',module='astropy.io.votables.tree')\n",
    "warnings.filterwarnings('ignore',message='.*unclosed..socket')\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, ICRS\n",
    "from astroquery.sdss import SDSS #package that allows queries of the SDSS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ea5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string ='''select\n",
    "  z, zerr\n",
    "from specobj\n",
    "where\n",
    "  ra between 175 and 185 and\n",
    "  dec between 7 and 17 and\n",
    "  class = 'galaxy' and\n",
    "  z between .002 and .006 and\n",
    "  zWarning = 0\n",
    "\n",
    "'''\n",
    "data = SDSS.query_sql(query_string,verbose=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=plt.hist(data['z'],10,histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['z'],data['zerr'],'ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_z = []\n",
    "std_z = []\n",
    "print(np.std(data['z']))\n",
    "\n",
    "p = plt.hist(data['z'],10,histtype='step',color='k',lw=3)\n",
    "\n",
    "for i in range(100):\n",
    "    zvalues = []\n",
    "    for z,zerr in zip(data['z'],data['zerr']):\n",
    "        zvalues.append(np.random.normal(z,zerr,1))\n",
    "    #print(i,np.std(zvalues))\n",
    "    zvalues = np.array(zvalues)\n",
    "    mean_z.append(np.mean(zvalues))\n",
    "    std_z.append(np.std(zvalues))\n",
    "    p = plt.hist(zvalues.flatten(),10,histtype='step',alpha=.5)\n",
    " \n",
    "print(np.median(std_z))\n",
    "std_z = np.array(std_z)\n",
    "mass = 2*7.5e6*9.461e17*(std_z*2.99e10)**2/6.67e-8/1.99e33\n",
    "mass_original = 2*7.5e6*9.461e17*(np.std(data['z']*2.99e10)**2)/6.67e-8/1.99e33/1e15\n",
    "print(mass_original)\n",
    "print(np.median(mass)/1e15,np.std(mass)/1e15)\n",
    "#p = plt.hist(mass/1e15,100,histtype='step')\n",
    "#plt.axvline(mass_original,color='k')\n",
    "#plt.axvline(np.median(mass/1e15),color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string ='''select\n",
    "  z,zerr\n",
    "from specobj\n",
    "where\n",
    "  ra between 28 and 30 and\n",
    "  dec between .5 and 1.5 and\n",
    "  class = 'galaxy' and\n",
    "  z between .05 and .11 and\n",
    "  zWarning = 0\n",
    "\n",
    "'''\n",
    "data = SDSS.query_sql(query_string,verbose=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2914b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=plt.hist(data['z'],20,histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed63995",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_z = []\n",
    "std_z = []\n",
    "print(np.std(data['z']))\n",
    "\n",
    "#p = plt.hist(data['z'],10,histtype='step',color='k',lw=3)\n",
    "\n",
    "for i in range(1000):\n",
    "    zvalues = []\n",
    "    for z,zerr in zip(data['z'],data['zerr']):\n",
    "        zvalues.append(np.random.normal(z,zerr,1))\n",
    "    #print(i,np.std(zvalues))\n",
    "    #zvalues = np.array(zvalues)\n",
    "    mean_z.append(np.mean(zvalues))\n",
    "    std_z.append(np.std(zvalues))\n",
    "    #p = plt.hist(zvalues.flatten(),10,histtype='step',alpha=.5)\n",
    " \n",
    "print(np.median(std_z))\n",
    "std_z = np.array(std_z)\n",
    "mass = 2*7.5e6*9.461e17*(std_z*2.99e10)**2/6.67e-8/1.99e33\n",
    "mass_original = 2*7.5e6*9.461e17*(np.std(data['z']*2.99e10)**2)/6.67e-8/1.99e33/1e15\n",
    "print(mass_original)\n",
    "print(np.median(mass)/1e15,np.std(mass)/1e15)\n",
    "p = plt.hist(mass/1e15,100,histtype='step')\n",
    "plt.axvline(mass_original,color='k')\n",
    "plt.axvline(np.median(mass/1e15),color='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
